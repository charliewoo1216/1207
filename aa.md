ì „ì²´ ì½”ë“œë¥¼ ì‘ì„±í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

## 1. í™˜ê²½ ì„¤ì • íŒŒì¼ (.env)

```plaintext
# .env íŒŒì¼ - í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìƒì„±
OPENAI_API_KEY=your-api-key-here
```

## 2. ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ (app.py)

```python
import streamlit as st
import os
from pathlib import Path
from dotenv import load_dotenv

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ê°„ë‹¨í•œ RAG ì‹œìŠ¤í…œ",
    page_icon="ğŸ“š",
    layout="wide"
)

# ìƒìˆ˜ ì •ì˜
DOCUMENTS_DIR = "documents"  # ë¬¸ì„œ í´ë”
VECTOR_STORE_PATH = "faiss_index"  # FAISS ì¸ë±ìŠ¤ ì €ì¥ ê²½ë¡œ


def load_documents(directory):
    """txt, md íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    documents = []
    
    # txt íŒŒì¼ ë¡œë“œ
    txt_loader = DirectoryLoader(
        directory,
        glob="**/*.txt",
        loader_cls=TextLoader,
        loader_kwargs={'encoding': 'utf-8'}
    )
    documents.extend(txt_loader.load())
    
    # md íŒŒì¼ ë¡œë“œ
    md_loader = DirectoryLoader(
        directory,
        glob="**/*.md",
        loader_cls=TextLoader,
        loader_kwargs={'encoding': 'utf-8'}
    )
    documents.extend(md_loader.load())
    
    return documents


def split_documents(documents):
    """ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• í•˜ëŠ” í•¨ìˆ˜"""
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,  # ì²­í¬ í¬ê¸°
        chunk_overlap=200,  # ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¶€ë¶„
        length_function=len,
    )
    splits = text_splitter.split_documents(documents)
    return splits


def create_vector_store(splits):
    """FAISS ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    embeddings = OpenAIEmbeddings()
    vectorstore = FAISS.from_documents(splits, embeddings)
    return vectorstore


def load_vector_store():
    """ì €ì¥ëœ FAISS ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    embeddings = OpenAIEmbeddings()
    vectorstore = FAISS.load_local(
        VECTOR_STORE_PATH, 
        embeddings,
        allow_dangerous_deserialization=True
    )
    return vectorstore


def create_qa_chain(vectorstore):
    """ì§ˆì˜ì‘ë‹µ ì²´ì¸ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    # LLM ì„¤ì •
    llm = ChatOpenAI(
        model_name="gpt-3.5-turbo",
        temperature=0
    )
    
    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    prompt_template = """ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”. 
    ë‹µë³€ì„ ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ê³ , ì–µì§€ë¡œ ë‹µë³€ì„ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.
    
    ì»¨í…ìŠ¤íŠ¸: {context}
    
    ì§ˆë¬¸: {question}
    
    ë‹µë³€:"""
    
    PROMPT = PromptTemplate(
        template=prompt_template,
        input_variables=["context", "question"]
    )
    
    # RetrievalQA ì²´ì¸ ìƒì„±
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=vectorstore.as_retriever(
            search_kwargs={"k": 3}  # ìƒìœ„ 3ê°œ ë¬¸ì„œ ê²€ìƒ‰
        ),
        return_source_documents=True,
        chain_type_kwargs={"prompt": PROMPT}
    )
    
    return qa_chain


def initialize_system():
    """ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜"""
    # documents í´ë” ìƒì„±
    if not os.path.exists(DOCUMENTS_DIR):
        os.makedirs(DOCUMENTS_DIR)
        st.info(f"ğŸ“ '{DOCUMENTS_DIR}' í´ë”ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì— txt, md íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")
        return None
    
    # ë¬¸ì„œ í™•ì¸
    doc_files = list(Path(DOCUMENTS_DIR).glob("**/*.txt")) + \
                list(Path(DOCUMENTS_DIR).glob("**/*.md"))
    
    if len(doc_files) == 0:
        st.warning(f"âš ï¸ '{DOCUMENTS_DIR}' í´ë”ì— txt ë˜ëŠ” md íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # FAISS ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if os.path.exists(VECTOR_STORE_PATH):
        with st.spinner("ğŸ’¾ ì €ì¥ëœ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ë¡œë“œì¤‘..."):
            vectorstore = load_vector_store()
            st.success("âœ… ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ!")
            return vectorstore
    else:
        # ìƒˆë¡œ ìƒì„±
        with st.spinner("ğŸ“š ë¬¸ì„œë¥¼ ë¡œë“œì¤‘..."):
            documents = load_documents(DOCUMENTS_DIR)
            st.info(f"ğŸ“„ {len(documents)}ê°œì˜ ë¬¸ì„œë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        
        with st.spinner("âœ‚ï¸ ë¬¸ì„œë¥¼ ë¶„í• ì¤‘..."):
            splits = split_documents(documents)
            st.info(f"ğŸ“ {len(splits)}ê°œì˜ ì²­í¬ë¡œ ë¶„í• í–ˆìŠµë‹ˆë‹¤.")
        
        with st.spinner("ğŸ”¢ ì„ë² ë”© ìƒì„± ë° ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶•ì¤‘..."):
            vectorstore = create_vector_store(splits)
            # FAISS ì¸ë±ìŠ¤ ì €ì¥
            vectorstore.save_local(VECTOR_STORE_PATH)
            st.success("âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ë° ì €ì¥ ì™„ë£Œ!")
        
        return vectorstore


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    st.title("ğŸ“š ê°„ë‹¨í•œ RAG ì‹œìŠ¤í…œ")
    st.markdown("---")
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # ë²¡í„° ìŠ¤í† ì–´ ì¬ìƒì„± ë²„íŠ¼
        if st.button("ğŸ”„ ë²¡í„° ìŠ¤í† ì–´ ì¬ìƒì„±"):
            if os.path.exists(VECTOR_STORE_PATH):
                import shutil
                shutil.rmtree(VECTOR_STORE_PATH)
                st.success("ë²¡í„° ìŠ¤í† ì–´ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”.")
                st.rerun()
        
        st.markdown("---")
        st.markdown("""
        ### ğŸ“– ì‚¬ìš© ë°©ë²•
        1. `documents` í´ë”ì— txt, md íŒŒì¼ ì¶”ê°€
        2. ì•± ì‹¤í–‰ (ìë™ìœ¼ë¡œ ë²¡í„°í™”)
        3. ì§ˆë¬¸ ì…ë ¥
        4. ë‹µë³€ í™•ì¸
        
        ### ğŸ’¡ íŒ
        - ë¬¸ì„œ ì¶”ê°€/ë³€ê²½ì‹œ 'ë²¡í„° ìŠ¤í† ì–´ ì¬ìƒì„±' í´ë¦­
        - API í‚¤ëŠ” .env íŒŒì¼ì— ì €ì¥
        """)
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    if 'vectorstore' not in st.session_state:
        st.session_state.vectorstore = initialize_system()
    
    if st.session_state.vectorstore is None:
        st.error("âŒ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # QA ì²´ì¸ ìƒì„±
    if 'qa_chain' not in st.session_state:
        st.session_state.qa_chain = create_qa_chain(st.session_state.vectorstore)
    
    # ì§ˆë¬¸ ì…ë ¥
    st.subheader("â“ ì§ˆë¬¸í•˜ê¸°")
    question = st.text_input(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
        placeholder="ì˜ˆ: ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    )
    
    # ë‹µë³€ ìƒì„±
    if st.button("ğŸ” ë‹µë³€ ë°›ê¸°", type="primary"):
        if question:
            with st.spinner("ğŸ¤” ë‹µë³€ ìƒì„±ì¤‘..."):
                result = st.session_state.qa_chain({"query": question})
                
                # ë‹µë³€ í‘œì‹œ
                st.markdown("### ğŸ’¬ ë‹µë³€")
                st.write(result['result'])
                
                # ì°¸ì¡° ë¬¸ì„œ í‘œì‹œ
                st.markdown("### ğŸ“„ ì°¸ì¡° ë¬¸ì„œ")
                for i, doc in enumerate(result['source_documents']):
                    with st.expander(f"ë¬¸ì„œ {i+1}: {doc.metadata.get('source', 'Unknown')}"):
                        st.write(doc.page_content)
        else:
            st.warning("âš ï¸ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")


if __name__ == "__main__":
    main()
```

## 3. ì‹¤í–‰ ë°©ë²•

```bash
# 1. í”„ë¡œì íŠ¸ í´ë” êµ¬ì¡° ìƒì„±
mkdir my_rag_project
cd my_rag_project

# 2. .env íŒŒì¼ ìƒì„± (ìœ„ ë‚´ìš© ë³µì‚¬)
# 3. app.py íŒŒì¼ ìƒì„± (ìœ„ ì½”ë“œ ë³µì‚¬)

# 4. documents í´ë”ì— txt, md íŒŒì¼ ì¶”ê°€
mkdir documents
# ì—¬ê¸°ì— í…ìŠ¤íŠ¸ íŒŒì¼ë“¤ì„ ë„£ìœ¼ì„¸ìš”

# 5. Streamlit ì•± ì‹¤í–‰
streamlit run app.py
```

## 4. ì£¼ìš” ê¸°ëŠ¥

âœ… **ìë™ ë¬¸ì„œ ë¡œë“œ**: documents í´ë”ì˜ txt, md íŒŒì¼ ìë™ ì¸ì‹
âœ… **FAISS-CPU ì‚¬ìš©**: ë¹ ë¥¸ ë¡œì»¬ ë²¡í„° ê²€ìƒ‰
âœ… **ì˜êµ¬ ì €ì¥**: ë²¡í„° ì¸ë±ìŠ¤ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ ì¬ì‚¬ìš©
âœ… **ì°¸ì¡° ë¬¸ì„œ í‘œì‹œ**: ë‹µë³€ì˜ ê·¼ê±°ê°€ ëœ ë¬¸ì„œ í™•ì¸ ê°€ëŠ¥
âœ… **ê°„ë‹¨í•œ UI**: Streamlitìœ¼ë¡œ ì§ê´€ì ì¸ ì¸í„°í˜ì´ìŠ¤ ì œê³µ

## 5. í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë¬¸ì„œ

`documents/sample.txt` íŒŒì¼ì„ ë§Œë“¤ì–´ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”:

```text
ì¸ê³µì§€ëŠ¥(AI)ì€ ì»´í“¨í„° ì‹œìŠ¤í…œì´ ì¸ê°„ì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.
ë¨¸ì‹ ëŸ¬ë‹ì€ AIì˜ í•˜ìœ„ ë¶„ì•¼ë¡œ, ë°ì´í„°ë¡œë¶€í„° í•™ìŠµí•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ ë‹¤ë£¹ë‹ˆë‹¤.
ë”¥ëŸ¬ë‹ì€ ì¸ê³µì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œ ì¢…ë¥˜ì…ë‹ˆë‹¤.
```

ì´ì œ ì•±ì„ ì‹¤í–‰í•˜ê³  "ì¸ê³µì§€ëŠ¥ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?"ì™€ ê°™ì€ ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”!
